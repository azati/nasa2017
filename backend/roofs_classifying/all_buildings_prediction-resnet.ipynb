{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 1070 (CNMeM is enabled with initial size: 80.0% of memory, cuDNN 5105)\n",
      "/usr/lib64/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from sys import version_info\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "except ImportError:\n",
    "    import pickle\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from scipy.misc import imread, imsave, imresize\n",
    "from lasagne.utils import floatX\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "import skimage\n",
    "from tqdm import tqdm\n",
    "from scipy.misc import imresize\n",
    "import xgboost\n",
    "import skimage.transform\n",
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from collections import Counter\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ResNet-50, network from the paper:\n",
    "# \"Deep Residual Learning for Image Recognition\"\n",
    "# http://arxiv.org/pdf/1512.03385v1.pdf\n",
    "# License: see https://github.com/KaimingHe/deep-residual-networks/blob/master/LICENSE\n",
    "\n",
    "# Download pretrained weights from:\n",
    "# https://s3.amazonaws.com/lasagne/recipes/pretrained/imagenet/resnet50.pkl\n",
    "\n",
    "import lasagne\n",
    "from lasagne.layers import InputLayer\n",
    "from lasagne.layers import Conv2DLayer as ConvLayer\n",
    "from lasagne.layers import BatchNormLayer\n",
    "from lasagne.layers import Pool2DLayer as PoolLayer\n",
    "from lasagne.layers import NonlinearityLayer\n",
    "from lasagne.layers import ElemwiseSumLayer\n",
    "from lasagne.layers import DenseLayer\n",
    "from lasagne.nonlinearities import rectify, softmax\n",
    "\n",
    "\n",
    "def build_simple_block(incoming_layer, names,\n",
    "                       num_filters, filter_size, stride, pad,\n",
    "                       use_bias=False, nonlin=rectify):\n",
    "    \"\"\"Creates stacked Lasagne layers ConvLayer -> BN -> (ReLu)\n",
    "    Parameters:\n",
    "    ----------\n",
    "    incoming_layer : instance of Lasagne layer\n",
    "        Parent layer\n",
    "    names : list of string\n",
    "        Names of the layers in block\n",
    "    num_filters : int\n",
    "        Number of filters in convolution layer\n",
    "    filter_size : int\n",
    "        Size of filters in convolution layer\n",
    "    stride : int\n",
    "        Stride of convolution layer\n",
    "    pad : int\n",
    "        Padding of convolution layer\n",
    "    use_bias : bool\n",
    "        Whether to use bias in conlovution layer\n",
    "    nonlin : function\n",
    "        Nonlinearity type of Nonlinearity layer\n",
    "    Returns\n",
    "    -------\n",
    "    tuple: (net, last_layer_name)\n",
    "        net : dict\n",
    "            Dictionary with stacked layers\n",
    "        last_layer_name : string\n",
    "            Last layer name\n",
    "    \"\"\"\n",
    "    net = []\n",
    "    net.append((\n",
    "            names[0],\n",
    "            ConvLayer(incoming_layer, num_filters, filter_size, stride, pad,\n",
    "                      flip_filters=False, nonlinearity=None) if use_bias\n",
    "            else ConvLayer(incoming_layer, num_filters, filter_size, stride, pad, b=None,\n",
    "                           flip_filters=False, nonlinearity=None)\n",
    "        ))\n",
    "\n",
    "    net.append((\n",
    "            names[1],\n",
    "            BatchNormLayer(net[-1][1])\n",
    "        ))\n",
    "    if nonlin is not None:\n",
    "        net.append((\n",
    "            names[2],\n",
    "            NonlinearityLayer(net[-1][1], nonlinearity=nonlin)\n",
    "        ))\n",
    "\n",
    "    return dict(net), net[-1][0]\n",
    "\n",
    "\n",
    "def build_residual_block(incoming_layer, ratio_n_filter=1.0, ratio_size=1.0, has_left_branch=False,\n",
    "                         upscale_factor=4, ix=''):\n",
    "    \"\"\"Creates two-branch residual block\n",
    "    Parameters:\n",
    "    ----------\n",
    "    incoming_layer : instance of Lasagne layer\n",
    "        Parent layer\n",
    "    ratio_n_filter : float\n",
    "        Scale factor of filter bank at the input of residual block\n",
    "    ratio_size : float\n",
    "        Scale factor of filter size\n",
    "    has_left_branch : bool\n",
    "        if True, then left branch contains simple block\n",
    "    upscale_factor : float\n",
    "        Scale factor of filter bank at the output of residual block\n",
    "    ix : int\n",
    "        Id of residual block\n",
    "    Returns\n",
    "    -------\n",
    "    tuple: (net, last_layer_name)\n",
    "        net : dict\n",
    "            Dictionary with stacked layers\n",
    "        last_layer_name : string\n",
    "            Last layer name\n",
    "    \"\"\"\n",
    "    simple_block_name_pattern = ['res%s_branch%i%s', 'bn%s_branch%i%s', 'res%s_branch%i%s_relu']\n",
    "\n",
    "    net = {}\n",
    "\n",
    "    # right branch\n",
    "    net_tmp, last_layer_name = build_simple_block(\n",
    "        incoming_layer, map(lambda s: s % (ix, 2, 'a'), simple_block_name_pattern),\n",
    "        int(lasagne.layers.get_output_shape(incoming_layer)[1]*ratio_n_filter), 1, int(1.0/ratio_size), 0)\n",
    "    net.update(net_tmp)\n",
    "\n",
    "    net_tmp, last_layer_name = build_simple_block(\n",
    "        net[last_layer_name], map(lambda s: s % (ix, 2, 'b'), simple_block_name_pattern),\n",
    "        lasagne.layers.get_output_shape(net[last_layer_name])[1], 3, 1, 1)\n",
    "    net.update(net_tmp)\n",
    "\n",
    "    net_tmp, last_layer_name = build_simple_block(\n",
    "        net[last_layer_name], map(lambda s: s % (ix, 2, 'c'), simple_block_name_pattern),\n",
    "        lasagne.layers.get_output_shape(net[last_layer_name])[1]*upscale_factor, 1, 1, 0,\n",
    "        nonlin=None)\n",
    "    net.update(net_tmp)\n",
    "\n",
    "    right_tail = net[last_layer_name]\n",
    "    left_tail = incoming_layer\n",
    "\n",
    "    # left branch\n",
    "    if has_left_branch:\n",
    "        net_tmp, last_layer_name = build_simple_block(\n",
    "            incoming_layer, map(lambda s: s % (ix, 1, ''), simple_block_name_pattern),\n",
    "            int(lasagne.layers.get_output_shape(incoming_layer)[1]*4*ratio_n_filter), 1, int(1.0/ratio_size), 0,\n",
    "            nonlin=None)\n",
    "        net.update(net_tmp)\n",
    "        left_tail = net[last_layer_name]\n",
    "\n",
    "    net['res%s' % ix] = ElemwiseSumLayer([left_tail, right_tail], coeffs=1)\n",
    "    net['res%s_relu' % ix] = NonlinearityLayer(net['res%s' % ix], nonlinearity=rectify)\n",
    "\n",
    "    return net, 'res%s_relu' % ix\n",
    "\n",
    "\n",
    "def build_model():\n",
    "    net = {}\n",
    "    net['input'] = InputLayer((None, 3, 224, 224))\n",
    "    sub_net, parent_layer_name = build_simple_block(\n",
    "        net['input'], ['conv1', 'bn_conv1', 'conv1_relu'],\n",
    "        64, 7, 2, 3, use_bias=True)\n",
    "    net.update(sub_net)\n",
    "    net['pool1'] = PoolLayer(net[parent_layer_name], pool_size=3, stride=2, pad=0, mode='max', ignore_border=False)\n",
    "    block_size = list('abc')\n",
    "    parent_layer_name = 'pool1'\n",
    "    for c in block_size:\n",
    "        if c == 'a':\n",
    "            sub_net, parent_layer_name = build_residual_block(net[parent_layer_name], 1, 1, True, 4, ix='2%s' % c)\n",
    "        else:\n",
    "            sub_net, parent_layer_name = build_residual_block(net[parent_layer_name], 1.0/4, 1, False, 4, ix='2%s' % c)\n",
    "        net.update(sub_net)\n",
    "\n",
    "    block_size = list('abcd')\n",
    "    for c in block_size:\n",
    "        if c == 'a':\n",
    "            sub_net, parent_layer_name = build_residual_block(\n",
    "                net[parent_layer_name], 1.0/2, 1.0/2, True, 4, ix='3%s' % c)\n",
    "        else:\n",
    "            sub_net, parent_layer_name = build_residual_block(net[parent_layer_name], 1.0/4, 1, False, 4, ix='3%s' % c)\n",
    "        net.update(sub_net)\n",
    "\n",
    "    block_size = list('abcdef')\n",
    "    for c in block_size:\n",
    "        if c == 'a':\n",
    "            sub_net, parent_layer_name = build_residual_block(\n",
    "                net[parent_layer_name], 1.0/2, 1.0/2, True, 4, ix='4%s' % c)\n",
    "        else:\n",
    "            sub_net, parent_layer_name = build_residual_block(net[parent_layer_name], 1.0/4, 1, False, 4, ix='4%s' % c)\n",
    "        net.update(sub_net)\n",
    "\n",
    "    block_size = list('abc')\n",
    "    for c in block_size:\n",
    "        if c == 'a':\n",
    "            sub_net, parent_layer_name = build_residual_block(\n",
    "                net[parent_layer_name], 1.0/2, 1.0/2, True, 4, ix='5%s' % c)\n",
    "        else:\n",
    "            sub_net, parent_layer_name = build_residual_block(net[parent_layer_name], 1.0/4, 1, False, 4, ix='5%s' % c)\n",
    "        net.update(sub_net)\n",
    "    net['pool5'] = PoolLayer(net[parent_layer_name], pool_size=7, stride=1, pad=0,\n",
    "                             mode='average_exc_pad', ignore_border=False)\n",
    "    net['fc1000'] = DenseLayer(net['pool5'], num_units=1000, nonlinearity=None)\n",
    "    net['prob'] = NonlinearityLayer(net['fc1000'], nonlinearity=softmax)\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels = pd.read_csv('data/merged_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "buildings_ids = df_labels['id'].values\n",
    "\n",
    "files_to_process = list(map(lambda ind: 'data/all_buildings/%05d.bmp' % ind, buildings_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = build_model()\n",
    "input_image = T.tensor4('input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('resnet50.pkl', 'rb') as f:\n",
    "    if version_info.major == 2:\n",
    "        resnet_weights = pickle.load(f)\n",
    "    elif version_info.major == 3:\n",
    "        resnet_weights = pickle.load(f, encoding='latin1')\n",
    "mean_values = resnet_weights['mean_image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lasagne.layers.set_all_param_values(net['prob'], resnet_weights['values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prep_image(fname):\n",
    "    if fname is None:\n",
    "        ext = url.split('.')[-1]\n",
    "        im = plt.imread(io.BytesIO(urllib.urlopen(url).read()), ext)\n",
    "    else:\n",
    "        ext = fname.split('.')[-1]\n",
    "        im = plt.imread(fname, ext)\n",
    "    h, w, _ = im.shape\n",
    "    if h < w:\n",
    "        im = skimage.transform.resize(im, (256, w*256/h), preserve_range=True)\n",
    "    else:\n",
    "        im = skimage.transform.resize(im, (h*256/w, 256), preserve_range=True)\n",
    "    h, w, _ = im.shape\n",
    "    im = im[h//2-112:h//2+112, w//2-112:w//2+112]\n",
    "    rawim = np.copy(im).astype('uint8')\n",
    "    im = np.swapaxes(np.swapaxes(im, 1, 2), 0, 1)\n",
    "    im = im[::-1, :, :]\n",
    "    im = im - mean_values\n",
    "    return rawim, floatX(im[np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_resnet_features(filenames, layer_name):\n",
    "    X = []    \n",
    "    input_image = T.tensor4('input')\n",
    "    output = lasagne.layers.get_output(net[layer_name], input_image, deterministic=True)\n",
    "    prob = theano.function([input_image], output) \n",
    "\n",
    "    for fname in tqdm(filenames):\n",
    "        raw_img, img = prep_image(fname)\n",
    "        features = prob(img).flatten()\n",
    "        X.append(features)\n",
    "    \n",
    "    return np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4464/4464 [01:50<00:00, 40.34it/s]\n"
     ]
    }
   ],
   "source": [
    "X5 = extract_resnet_features(files_to_process, 'pool5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.concatenate([X5], axis=1)\n",
    "X = np.sqrt(np.abs(X))\n",
    "Y = df_labels['is_flat'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm', SVC(C=10))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.882550, total=  26.8s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   26.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.893736, total=  26.7s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   53.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.906951, total=  27.4s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  1.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.873318, total=  27.1s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  1.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.893498, total=  27.4s\n",
      "Mean score:  0.890010633922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  2.3min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  2.3min finished\n"
     ]
    }
   ],
   "source": [
    "res = cross_val_score(model, X, Y, cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=10), verbose=10)\n",
    "print('Mean score: ', np.mean(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_files_to_process = map(lambda x: 'data/all_buildings/%s' % x, os.listdir('data/all_buildings/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25747/25747 [08:37<00:00, 49.77it/s]\n"
     ]
    }
   ],
   "source": [
    "X_all = extract_resnet_features(all_files_to_process, 'pool5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_all_transformed = np.sqrt(np.abs(X_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('svm', SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False))])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_predictions = model.predict(X_all_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = []\n",
    "for index, fname in enumerate(all_files_to_process):\n",
    "    if fname == 'data/all_buildings/%05d.bmp':\n",
    "        continue\n",
    "    tmp = int(fname.split('/')[-1].split('.')[0])\n",
    "    pred = all_predictions[index]\n",
    "    res.append([tmp, pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_results = pd.DataFrame(res, columns=['id', 'is_flat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_results.to_csv('data/all_results_grodno.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
